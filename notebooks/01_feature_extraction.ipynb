{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Get Audio from Spotify ID:\n",
    "Below is an implementation that allows you to get an audio track as a numpy array from its spotify track ID.\n",
    "To clean up the project and prevent large storage size, uncomment the try block which cleans up the 'temp_audio.wav' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import yt_dlp\n",
    "import librosa\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import soundfile as sf\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_audio_array(track_id, duration=30, sr=44100):\n",
    "    \"\"\"\n",
    "    Get audio as numpy array from Spotify track ID using YouTube.\n",
    "    \"\"\"\n",
    "    # Initialize Spotify client\n",
    "    try:\n",
    "        auth_manager = SpotifyClientCredentials(\n",
    "            client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "            client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n",
    "        )\n",
    "        sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "        \n",
    "        # Get track info from Spotify\n",
    "        track = sp.track(track_id)\n",
    "        track_name = track['name']\n",
    "        artist_name = track['artists'][0]['name']\n",
    "        logger.info(f\"Fetching: {track_name} by {artist_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching Spotify track {track_id}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # YouTube download options\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': 'temp_audio.%(ext)s',\n",
    "        'quiet': True,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "        }],\n",
    "    }\n",
    "    \n",
    "    # Download audio from YouTube\n",
    "    search_query = f\"{track_name} {artist_name} official audio\"\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.extract_info(f\"ytsearch1:{search_query}\", download=True)\n",
    "        \n",
    "        # Load audio with explicit duration handling\n",
    "        audio, original_sr = librosa.load('temp_audio.wav', sr=sr, mono=True)\n",
    "        \n",
    "        # Manually truncate to exact duration\n",
    "        target_samples = duration * sr\n",
    "        if len(audio) > target_samples:\n",
    "            audio = audio[:target_samples]\n",
    "        elif len(audio) < target_samples:\n",
    "            # Pad if shorter than requested duration\n",
    "            audio = np.pad(audio, (0, target_samples - len(audio)))\n",
    "            \n",
    "        logger.info(f\"Audio loaded: {len(audio)/sr:.2f}s, {sr}Hz, shape: {audio.shape}\")\n",
    "        return audio\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error downloading audio for {track_id}: {e}\")\n",
    "        try:\n",
    "            os.remove('temp_audio.wav')\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "def get_track_name(track_id):\n",
    "    \"\"\"Helper function to get track name for filename\"\"\"\n",
    "    try:\n",
    "        auth_manager = SpotifyClientCredentials(\n",
    "            client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "            client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n",
    "        )\n",
    "        sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "        track = sp.track(track_id)\n",
    "        track_name = track['name'].replace(' ', '_').replace('/', '_')  # Make filename safe\n",
    "        artist_name = track['artists'][0]['name'].replace(' ', '_').replace('/', '_')\n",
    "        return f\"{artist_name}_{track_name}\"\n",
    "    except:\n",
    "        return \"audio\"\n",
    "\n",
    "# Example usage\n",
    "\n",
    "track_id = \"4cEN3svbqObdDpaZiv9sWP\"  # Example Spotify track ID\n",
    "track_name = get_track_name(track_id)\n",
    "    \n",
    "audio = get_audio_array(track_id, duration=30, sr=44100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### DSP Pipeline\n",
    "\n",
    "##### 1. Convert to Mono\n",
    "The first step in the signal processing pipeline is to convert the audio to mono, which librosa does when we load the audio file into an array.\n",
    "\n",
    "##### 2. Harmonic and Percussive Source Separation (HPSS)\n",
    "Splitting the audio signal into its harmonic and percussive components allows for cleaner signals to be analyzed. For key estimation, only the harmonic content is used which prevents the percussive frequencies that do not correspond to the key of the audio from effecting the estimation. Similarly, for tempo estimation, only the percussive signal is analyzed as teh percussion tends to show clearer rhythmic patterns which the model will more easily be able to detect and ascribe a BPM label to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_dsp(audio, sr=44100):\n",
    "    \"\"\"\n",
    "    Perform DSP analysis with proper time scaling and layout.\n",
    "    Returns harmonic and percussive audio arrays.\n",
    "    \"\"\"\n",
    "    # Verify audio properties\n",
    "    duration = len(audio) / sr\n",
    "    print(f\"Processing audio: {duration:.2f}s, {len(audio)} samples\")\n",
    "    \n",
    "    # Compute STFT with appropriate parameters\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    \n",
    "    stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    # Harmonic-percussive separation with tuned parameters\n",
    "    harmonic, percussive = librosa.decompose.hpss(stft, kernel_size=(13, 31))\n",
    "    \n",
    "    # Reconstruct time-domain signals\n",
    "    harmonic_audio = librosa.istft(harmonic, hop_length=hop_length, length=len(audio))\n",
    "    percussive_audio = librosa.istft(percussive, hop_length=hop_length, length=len(audio))\n",
    "    \n",
    "    # Normalize for consistency (prevent clipping)\n",
    "    harmonic_audio = harmonic_audio / np.max(np.abs(harmonic_audio)) if np.max(np.abs(harmonic_audio)) != 0 else harmonic_audio\n",
    "    percussive_audio = percussive_audio / np.max(np.abs(percussive_audio)) if np.max(np.abs(percussive_audio)) != 0 else percussive_audio\n",
    "    \n",
    "    # Plot (existing code)\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    gs = plt.GridSpec(4, 2, figure=fig, height_ratios=[1, 1, 1, 0.1], hspace=0.3)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    img1 = librosa.display.specshow(\n",
    "        librosa.amplitude_to_db(np.abs(stft), ref=np.max),\n",
    "        y_axis='log', x_axis='time', sr=sr, hop_length=hop_length, ax=ax1\n",
    "    )\n",
    "    ax1.set(title=f'Full Spectrogram ({duration:.1f}s)')\n",
    "    ax1.label_outer()\n",
    "    \n",
    "    # Harmonic spectrogram\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    img2 = librosa.display.specshow(\n",
    "        librosa.amplitude_to_db(np.abs(harmonic), ref=np.max(np.abs(stft))),\n",
    "        y_axis='log', x_axis='time', sr=sr, hop_length=hop_length, ax=ax2\n",
    "    )\n",
    "    ax2.set(title='Harmonic Component')\n",
    "    ax2.label_outer()\n",
    "    \n",
    "    # Percussive spectrogram\n",
    "    ax3 = fig.add_subplot(gs[2, :])\n",
    "    img3 = librosa.display.specshow(\n",
    "        librosa.amplitude_to_db(np.abs(percussive), ref=np.max(np.abs(stft))),\n",
    "        y_axis='log', x_axis='time', sr=sr, hop_length=hop_length, ax=ax3\n",
    "    )\n",
    "    ax3.set(title='Percussive Component')\n",
    "    ax3.set_xlabel('Time (seconds)')\n",
    "    \n",
    "    cax = fig.add_subplot(gs[3, :])\n",
    "    fig.colorbar(img1, cax=cax, orientation='horizontal', format='%+2.0f dB')\n",
    "    cax.set_xlabel('Power (dB)')\n",
    "    \n",
    "    plt.subplots_adjust(top=0.95, bottom=0.08, left=0.08, right=0.92, hspace=0.4)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"STFT shape: {stft.shape}\")\n",
    "    print(f\"Frequency bins: {stft.shape[0]}, Time frames: {stft.shape[1]}\")\n",
    "    \n",
    "    # Return the reconstructed audio\n",
    "    return harmonic_audio, percussive_audio\n",
    "\n",
    "if audio is not None:\n",
    "     harmonic_audio, percussive_audio = perform_dsp(audio, sr=44100)\n",
    "    #harmonic, percussive = simple_separation_playback(audio, track_name=track_name) # comment this line to improve performance - this is just to check the hpss output\n",
    "        \n",
    "\n",
    "else:\n",
    "    print(\"Failed to get audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "##### 3. Constant Q-Ttransform Chroma Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_cqt_spec(audio, sr=44100):\n",
    "    \"\"\"\n",
    "    Perform DSP analysis with proper time scaling and layout\n",
    "    \"\"\"\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(chroma_cqt, x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
    "    plt.colorbar(label='Intensity')\n",
    "    plt.title('Constant-Q Chroma Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if harmonic_audio is not None:\n",
    "    chroma_cqt_spec(harmonic_audio, sr=44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
